# 第一章 机器学习和优化

这本书的读者对机器学习或者是深度学习的概念一定不陌生，机器学习算法，尤其是深度学习，最终总是会划归成求解一个函数极小值的形式，这个函数通常我们称为损失函数，用来衡量模型预测结果是实际数据之间差异。

## 第一节 从优化讲起

在本节中，我想以一个简单的线性回归为例作为引入，目的是让你们了解优化（Optimization）在整个机器学习算法中起到的重要作用。不夸张得说，大部分机器学习算法都能用优化方法求解，尤其是当损失函数非凸（接下来我会介绍这个概念）时，常见的优化算法比如随机梯度下降（stochastic gradient descent, SGD）发挥着至关重要的作用。下面就让我们用一个非常简单的线性回归实例来作为引入。



### 1.1 一个线性回归的实例

> 这个例子改编自笔者入门机器学习所用的书籍 [A first Course in Machine Learning](http://www.dcs.gla.ac.uk/~srogers/firstcourseml/) , 作者是 Simon Rogers 教授，这本书里从初学者的视角以非常详尽的数学推导展示机器学习的几个基础且重要的算法，强烈建议有时间的同学可以读一读。

假如我们想要对历届奥运会男子100米金牌选手的比赛成绩(耗时)做预测，一份从1896年到2008年收集到的数据如下所示。每一行用逗号分隔了两个数字，分别是奥运会举办的届数和夺冠耗时。比如$1,12$代表第一届奥运会（1896年）男子100米金牌选手夺冠耗时12秒。

```python
# olympic100m.txt
1,12
2,11
3,11
4,11.2
5,10.8
6,10.8
7,10.8
8,10.6
9,10.8
10,10.3
11,10.3
12,10.3
13,10.4
14,10.5
15,10.2
16,10
17,9.95
18,10.14
19,10.06
20,10.25
21,9.99
22,9.92
23,9.96
24,9.84
25,9.87
26,9.85
27,9.69
```

有了这份数据，一个常见的机器学习任务是对2012年第28奥运会夺冠耗时做一个预测。在求解机器学习问题之前，一个好习惯是将已知的数据形象得表示出来，以便观察数据的基本形式，发现可能存在的问题（比如异常点、离群点）等等。

```python
# codes/1-1.py
from matplotlib import pyplot as plt
plt.rcParams['font.sans-serif'] = ['Arial Unicode MS'] # 支持中文字体

# 载入数据
data = np.loadtxt('olympic100m.txt', delimiter=',')
num = data[:,0]
time = data[:,1]

# 画出数据方便观察
plt.plot(num,time,'ro')
plt.xlabel('奥运会届数')
plt.ylabel('夺冠耗时(秒)')
plt.show()
```

上面的代码中，我们先从 `olympic100m.txt` 这个文本文件中把数据读取出来，分别赋予到 `num` 和 `time` 两个列向量中，再将他们画到图上：

![image-20210428203252527](https://tva1.sinaimg.cn/large/008i3skNly1gpzqicr897j30hs0dcwer.jpg)

从图中可以看出，横轴奥运会举办年份和纵轴夺冠耗时之间呈比较明显的**线性关系**，这是能使用机器学习方法进行学习的前提，如果数据之间的关系是杂乱无章的，我们很难设计行之有效的方法来进行预测。

既然年份和耗时之间有这么明显的线性关系，下面我们使用机器学习方法来求解具体的线性关系，我们使用的模型叫做 **线性回归**。

### 1.2 线性回归

线性回归中的线性是指自变量奥运会举办年份`year`和因变量夺冠耗时`time`之间的关系是线性的。如果从二维图像上来看，`num`和`time`可以被一条直线很好的穿过，首先我们忽略其中的推导求解，将这条直线绘制出来如下图所示：

![image-20210428203722720](https://tva1.sinaimg.cn/large/008i3skNly1gpzqmzycmhj30hs0dc0t7.jpg)

这样理解线性回归就很直观了，所谓线性回归，指变量之间的关系可以用如下一次方函数表示：
$$
a_1\times \text{num} + a_2\times\text{time}+a_3=0
$$
其中$a_1,a_2,a_3$都是参数，机器学习的任务就是从数据中学习到$a_1, a_2, a_3$具体的数值，又叫做参数拟合。

但是，我们只有两个变量`num`和`time`，线性模型真的需要拟合3个参数吗？答案是否定的，如果等式两边同时乘以$\frac{1}{a_3}, a_3 \ne 0$，我们可以得到下面的等式：
$$
\frac{a_1}{a_3}\times\text{num} + \frac{a_2}{a_3}\times\text{time}+1=0
$$

> 如果$a_3=0$，那么上式将会退化成更加简单的形式，此时线性回归所拟合的直线将是过原点的一条直线，对应需要拟合的参数只有一个。

再做一下变量替换令$w_1=\frac{a_1}{a_3},w_2=\frac{a_2}{a_3}$，我们就能得到这样的漂亮形式：
$$
w_1\times\text{num}+w_2\times\text{time}+1=0
$$
这个就是线性回归的基本形式，我们发现，在线性模型中，如果有两个变量，那么对应的需要拟合的参数就只有两个。因此线性回归的任务就是从历史的已知数据中找出合适的$w_1,w_2$。求解这两个参数有很多方法，下面我要介绍和优化最为相关的方法，并以此作为引子，来聊一聊深度学习框架到底要做什么。

### 1.3 线性回归问题求解

寻求解决一个问题的方法，最重要是的确认目标是什么。在我们的奥运会例子中，我们的目标是要找到最理想的$w_1,w_2$，使得对于所有历史数据`num`和`time`，$w_1\times\text{year}+w_2\times\text{time}+1$ 都能近似等于0。比如从数据表中我们可以看出，第一届奥运会夺冠耗时12秒，因此我们希望$w_1\times1+w_2\times12+1=0$。如果计算结果不为0，我们称这个值叫误差$l$，即$l=w_1\times1+w_2\times12+1$。为了便于讨论，我们需要对符号进行一些变化。

在`olympic100m.txt`中，我们一共有27条数据，每一条数据我们称为一条样本，对于第$i$个样本，我们将奥运会的举办届数记为$n_i$，选手夺冠耗时记为$t_i$，对给定$w_1,w_2$，模型拟合样本$i$的误差$l_i$定义为$l_i=w_1n_i+w_2t_i+1$，为使得对所有的历史数据$n_i,t_i,i=1\cdots27$，模型都能作出很好的拟合，我们要求每个$l_i$都趋近于0，即总损失
$$
\mathcal{L}=\sum_{i=1}^{27}|l_i|=\sum_{i=1}^{27}|w_1n_i+w_2t_i+1|
$$
越小越好。

在上式中为什么我们求解的是每个样本损失$l_i$的绝对值的和？考虑这么一个例子，假如对于某个特定的$w_1,w_2$，通过计算，对于第一个样本来说，通过计算$l_1=-5$，对于第二个样本来说，通过计算$l_2=5$，$w_1,w_2$这组参数组成的线性回归模型都没有很好得拟合这两个样本，因此$l_1$和$l_2$均不为0，但是如果我们直接将它们相加，总损失却等于0，这是不符合期望的。因此我们需要对每个样本的损失计算绝对值再相加。

在机器学习中，通常我们不会直接使用绝对值符号，因为它不是处处可微分的，后文中会再详细解释为什么这个性质这么重要。我们通常计算每个样本损失的平方再求均值作为整体损失，平方函数是处处可微分的，因此损失函数变成了这样：
$$
\mathcal{L}=\sum_{i=1}^{27}l_i^2=\frac{1}{27}\sum_{i=1}^{27}(w_1n_i+w_2t_i+1)^2
$$
讲了这么多，我觉得还是将整个损失函数和$w_1,w_2$的关系画出来，方便大家有个直观地认识：

![image-20210428214228924](https://tva1.sinaimg.cn/large/008i3skNly1gpzsisukbdj30hs0dc76i.jpg)

上图中清晰地展示了$w_1,w_2$取不同的值对$\mathcal{L}$的影响。